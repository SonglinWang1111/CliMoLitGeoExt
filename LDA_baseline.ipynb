{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6d79e6-1437-4380-b818-f29c8028c615",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d96b6b-ae31-458e-81fc-70664343ae01",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation, or LDA, is a 3-level hierarchical Bayesian model. Put it differently, it is a generative statistic model that explains how a collection of text documents can be described by a set of unobserved topics. Each item of the collection is modelled as a finite mixture over a latent set of topics here, while each topic is characterized by a distribution of words. As a generalization of pLSA model, it differs primarily by treating the topic mixture as a Dirichlet prior, leading to more reasonable mixtures and less susceptibility to overfitting. LDA is an important model in NLP, solving the problem of topic discovery, similarity comparison, document modeling and classification.\n",
    "\n",
    "As for more detail of this model, basically, it is a Bag-of-Word based model, based on word co-occurrance. It considers that a piece of text is composed of many words, without considering order. One piece of text can have many topics, while each word from it is generated by one of the topics. The first step of this model is, to get document i a topic distribution theta(i) from Dirichlet distribution alpha. Then, from theta(i), it gets topic number j for document i as z(i,j). Next, from Dirichlet distribution beta, it generates the word distribution of z(i,j) then sample the final word w(i,j). With maximum likelihood and EM odel, we can get the final result. In summary, alpha and beta are corpus level parameters, and z and w are word level variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc8d25-157b-4c2d-9539-47e475ffd631",
   "metadata": {},
   "source": [
    "![LDA](Latent_Dirichlet_allocation.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27cd0a-3a02-4031-84a0-0f774445aebc",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ea64f4-a5e9-45d8-b8cf-c4c4b82df245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.parsing.preprocessing import preprocess_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad654c65-729a-4d48-91f8-575deb8cb9a0",
   "metadata": {},
   "source": [
    "### Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c42213-315b-4db4-8ee0-577fae53789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('literature.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275053c9-d3cb-4ce0-bde1-678bc5342d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract papers from dictionary and save in a list\n",
    "texts = []\n",
    "\n",
    "for _, sections in data.items():\n",
    "    full_text = \" \".join(sections.values())\n",
    "    texts.append(full_text)\n",
    "\n",
    "# function from gensim, can delete stop words, transfer to lower case, etc.\n",
    "processed_texts = [preprocess_string(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ba0085-1513-4f43-bfa2-e0e187af69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(processed_texts) # construct dictionary from the papers\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts] # construct corpus, each paper is transferred into a list of (word_id, word_count) tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d50226-6fc2-4985-ae58-e054a1b07733",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa9b381-1bf2-4ee5-b64b-5ffbac8d2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=50, passes=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73540514-6a75-46df-a248-53b219f734e6",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd595a93-0433-471f-87de-7f7301447b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "\n",
    "for _, bow in enumerate(corpus):\n",
    "    dist = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    topic = np.array([prob for _, prob in dist])\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048f7b49-b00f-4052-b2bf-304c0abe8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper 0's topic might be 33\n",
      "paper 1's topic might be 19\n",
      "paper 2's topic might be 49\n",
      "paper 3's topic might be 31\n",
      "paper 4's topic might be 1\n",
      "paper 5's topic might be 31\n",
      "paper 6's topic might be 4\n",
      "paper 7's topic might be 8\n",
      "paper 8's topic might be 8\n",
      "paper 9's topic might be 25\n",
      "paper 10's topic might be 7\n",
      "paper 11's topic might be 40\n",
      "paper 12's topic might be 42\n",
      "paper 13's topic might be 23\n",
      "paper 14's topic might be 35\n",
      "paper 15's topic might be 29\n",
      "paper 16's topic might be 25\n",
      "paper 17's topic might be 5\n",
      "paper 18's topic might be 33\n",
      "paper 19's topic might be 8\n",
      "paper 20's topic might be 7\n",
      "paper 21's topic might be 29\n",
      "paper 22's topic might be 1\n",
      "paper 23's topic might be 35\n",
      "paper 24's topic might be 7\n",
      "paper 25's topic might be 35\n",
      "paper 26's topic might be 14\n",
      "paper 27's topic might be 21\n",
      "paper 28's topic might be 8\n",
      "paper 29's topic might be 21\n"
     ]
    }
   ],
   "source": [
    "for i, bow in enumerate(corpus):\n",
    "    dist = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    topic = max(dist, key=lambda x: x[1])[0]\n",
    "\n",
    "    print(f\"paper {i}'s topic might be {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8e1c5-dc6b-47a3-b080-58070010d20e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b70c84-f4d3-4484-94a4-b54ab86cbe1f",
   "metadata": {},
   "source": [
    "LDA can automize text classification part, however, it can not really assign text with externally defined codes, especially when pre-defined class names are not present in the dictionary. Thus, usually we have to manually annotate the papers based on topics we get, top words of such topics, and the matching topic of each paper. But anyway, it can lower the workload compared with doing fully manual annotation. Here we first take paper 0 for evaluation. Its topic is likely to be 33 according to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe7648a6-1a4b-445b-b4fc-a0cb59819bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.040*\"migrat\" + 0.024*\"environment\" + 0.023*\"household\" + 0.016*\"event\" + 0.013*\"individu\" + 0.010*\"climat\" + 0.010*\"migrant\" + 0.010*\"commun\" + 0.009*\"stressor\" + 0.009*\"chang\" + 0.009*\"intent\" + 0.008*\"zone\" + 0.008*\"relat\" + 0.008*\"head\" + 0.008*\"studi\" + 0.007*\"peopl\" + 0.007*\"transit\" + 0.007*\"like\" + 0.007*\"level\" + 0.006*\"respond\" + 0.006*\"affect\" + 0.006*\"term\" + 0.006*\"ghana\" + 0.006*\"econom\" + 0.006*\"decis\" + 0.006*\"variabl\" + 0.005*\"educ\" + 0.005*\"countri\" + 0.005*\"differ\" + 0.005*\"result\" + 0.005*\"factor\" + 0.005*\"model\" + 0.004*\"land\" + 0.004*\"adapt\" + 0.004*\"non\" + 0.004*\"impact\" + 0.004*\"member\" + 0.004*\"forest\" + 0.004*\"percept\" + 0.004*\"major\" + 0.004*\"savannah\" + 0.004*\"includ\" + 0.003*\"area\" + 0.003*\"effect\" + 0.003*\"associ\" + 0.003*\"long\" + 0.003*\"rural\" + 0.003*\"intern\" + 0.003*\"year\" + 0.003*\"black\" + 0.003*\"ag\" + 0.003*\"crop\" + 0.003*\"agricultur\" + 0.003*\"influenc\" + 0.003*\"survei\" + 0.003*\"sudden\" + 0.003*\"stai\" + 0.003*\"control\" + 0.003*\"develop\" + 0.003*\"locat\" + 0.003*\"hunter\" + 0.003*\"region\" + 0.003*\"increas\" + 0.003*\"incom\" + 0.003*\"indic\" + 0.003*\"rainfal\" + 0.003*\"examin\" + 0.003*\"provid\" + 0.003*\"type\" + 0.003*\"farmer\" + 0.003*\"higher\" + 0.003*\"strategi\" + 0.003*\"social\" + 0.002*\"research\" + 0.002*\"popul\" + 0.002*\"demograph\" + 0.002*\"data\" + 0.002*\"drought\" + 0.002*\"sever\" + 0.002*\"flood\" + 0.002*\"vulner\" + 0.002*\"mention\" + 0.002*\"reason\" + 0.002*\"resourc\" + 0.002*\"tabl\" + 0.002*\"current\" + 0.002*\"short\" + 0.002*\"livelihood\" + 0.002*\"onset\" + 0.002*\"bush\" + 0.002*\"time\" + 0.002*\"depend\" + 0.002*\"experienc\" + 0.002*\"compar\" + 0.002*\"gradual\" + 0.002*\"score\" + 0.002*\"relationship\" + 0.002*\"sampl\" + 0.002*\"respons\" + 0.002*\"statu\" + 0.002*\"likelihood\" + 0.002*\"socio\" + 0.002*\"addit\" + 0.002*\"signific\" + 0.002*\"import\" + 0.002*\"half\" + 0.002*\"averag\" + 0.002*\"consid\" + 0.002*\"adger\" + 0.002*\"perceiv\" + 0.002*\"instanc\" + 0.002*\"urban\" + 0.002*\"lower\" + 0.002*\"specif\" + 0.002*\"environ\" + 0.002*\"van\" + 0.002*\"base\" + 0.002*\"difficult\" + 0.002*\"find\" + 0.002*\"gss\" + 0.002*\"suggest\" + 0.002*\"challeng\" + 0.002*\"recent\" + 0.002*\"determin\" + 0.002*\"high\" + 0.002*\"characterist\" + 0.002*\"polit\" + 0.002*\"set\" + 0.002*\"empir\" + 0.002*\"food\" + 0.002*\"gener\" + 0.002*\"place\" + 0.002*\"abl\" + 0.002*\"issu\" + 0.002*\"report\" + 0.002*\"address\" + 0.002*\"expect\" + 0.002*\"probabl\" + 0.001*\"stress\" + 0.001*\"easili\" + 0.001*\"follow\" + 0.001*\"measur\" + 0.001*\"risk\" + 0.001*\"lead\" + 0.001*\"us\" + 0.001*\"size\" + 0.001*\"live\" + 0.001*\"opportun\" + 0.001*\"case\" + 0.001*\"statist\" + 0.001*\"low\" + 0.001*\"number\" + 0.001*\"support\" + 0.001*\"polici\" + 0.001*\"exampl\" + 0.001*\"marri\" + 0.001*\"new\" + 0.001*\"irregular\" + 0.001*\"hand\" + 0.001*\"contribut\" + 0.001*\"poor\" + 0.001*\"focu\" + 0.001*\"condit\" + 0.001*\"actual\" + 0.001*\"identifi\" + 0.001*\"final\" + 0.001*\"cost\" + 0.001*\"lack\" + 0.001*\"tend\" + 0.001*\"ask\" + 0.001*\"concern\" + 0.001*\"understand\" + 0.001*\"natur\" + 0.001*\"product\" + 0.001*\"assess\" + 0.001*\"experi\" + 0.001*\"significantli\" + 0.001*\"reli\" + 0.001*\"person\" + 0.001*\"slow\" + 0.001*\"usual\" + 0.001*\"order\" + 0.001*\"regard\" + 0.001*\"indigen\" + 0.001*\"share\" + 0.001*\"second\" + 0.001*\"storm\" + 0.001*\"mcleman\" + 0.001*\"africa\" + 0.001*\"inform\" + 0.001*\"decid\" + 0.001*\"farm\" + 0.001*\"potenti\" + 0.001*\"futur\" + 0.001*\"problem\" + 0.001*\"role\" + 0.001*\"main\" + 0.001*\"der\" + 0.001*\"process\" + 0.001*\"show\"\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topic(33, topn=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "884bf44b-e1cf-4e88-88d6-dea8daf6fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 1, 1, 1, \\\n",
    "        1, 1, 1, 0, 0, \\\n",
    "        1, 1, 1, 1, \\\n",
    "        1, 0, 1, 1, \\\n",
    "        1, 1, 1, \\\n",
    "        0, 1, 0, 0, 0, 0, \\\n",
    "        0, 0, 0, 1, 1, 0, 0, \\\n",
    "        0, 1, 0]]\n",
    "result = pd.DataFrame(data, columns=['Qualitative method', 'Quantitative method', 'Socio-demo-economic data', 'Environmental data', \\\n",
    "                       'Individuals', 'Households', 'Subnational groups', 'National groups', 'International groups', \\\n",
    "                       'Urban', 'Rural', 'Time frame considered', 'Foresight', \\\n",
    "                       'Rainfall pattern / Variability', 'Temperature change', 'Food scarcity / Famine / Food security', 'Drought / Aridity / Desertification', \\\n",
    "                       'Floods', 'Erosion / Soil fertility / Land degradation / Deforestation / Salinisation', 'Self assessment / Perceived environment', \\\n",
    "                       'Labour migration', 'Marriage migration', 'Refugees', 'International migration', 'Cross-border migration', 'Internal migration', \\\n",
    "                       'Rural to urban', 'Rural to rural', 'Circular / Seasonal', 'Long distance', 'Short distance', 'Temporal', 'Permanent', \\\n",
    "                       'Age', 'Gender', 'Ethnicity / Religion']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfd92dcd-3304-439d-bbb9-ca0c0a582e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_result = pd.read_excel('manual.xlsx').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8702118-7184-4bc9-8c47-45a3f7dcc101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qualitative method</th>\n",
       "      <th>Quantitative method</th>\n",
       "      <th>Socio-demo-economic data</th>\n",
       "      <th>Environmental data</th>\n",
       "      <th>Individuals</th>\n",
       "      <th>Households</th>\n",
       "      <th>Subnational groups</th>\n",
       "      <th>National groups</th>\n",
       "      <th>International groups</th>\n",
       "      <th>Urban</th>\n",
       "      <th>...</th>\n",
       "      <th>Rural to urban</th>\n",
       "      <th>Rural to rural</th>\n",
       "      <th>Circular / Seasonal</th>\n",
       "      <th>Long distance</th>\n",
       "      <th>Short distance</th>\n",
       "      <th>Temporal</th>\n",
       "      <th>Permanent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity / Religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Qualitative method Quantitative method Socio-demo-economic data  \\\n",
       "0                  0                   1                        1   \n",
       "\n",
       "  Environmental data Individuals Households Subnational groups  \\\n",
       "0                  1           0          1                  0   \n",
       "\n",
       "  National groups International groups Urban  ... Rural to urban  \\\n",
       "0               0                    0     0  ...              0   \n",
       "\n",
       "  Rural to rural Circular / Seasonal Long distance Short distance Temporal  \\\n",
       "0              0                   0             0              0        0   \n",
       "\n",
       "  Permanent Age Gender Ethnicity / Religion  \n",
       "0         0   1      1                    0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_result = manual_result.iloc[[3]].drop(columns=['ID', 'AUTHOR', 'TITLE']).reset_index(drop=True)\n",
    "manual_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d238181d-6efc-49f6-a73b-d2ab7541ba27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6111111111111112)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_result = (result.iloc[0] == manual_result.iloc[0])\n",
    "bool_result.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3c006-c31d-45d7-acb2-0e7336ba024c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myGeoKG",
   "language": "python",
   "name": "mygeokg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
